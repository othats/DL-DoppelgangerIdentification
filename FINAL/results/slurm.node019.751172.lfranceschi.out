Using cuda device
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
ResNet                                   [128, 512, 1, 1]          513,000
├─Conv2d: 1-1                            [128, 64, 128, 128]       9,408
├─BatchNorm2d: 1-2                       [128, 64, 128, 128]       128
├─ReLU: 1-3                              [128, 64, 128, 128]       --
├─MaxPool2d: 1-4                         [128, 64, 64, 64]         --
├─Sequential: 1-5                        [128, 64, 64, 64]         --
│    └─ResidualBlock: 2-1                [128, 64, 64, 64]         --
│    │    └─Conv2d: 3-1                  [128, 64, 64, 64]         36,864
│    │    └─BatchNorm2d: 3-2             [128, 64, 64, 64]         128
│    │    └─ReLU: 3-3                    [128, 64, 64, 64]         --
│    │    └─Conv2d: 3-4                  [128, 64, 64, 64]         36,864
│    │    └─BatchNorm2d: 3-5             [128, 64, 64, 64]         128
│    │    └─ReLU: 3-6                    [128, 64, 64, 64]         --
│    └─ResidualBlock: 2-2                [128, 64, 64, 64]         --
│    │    └─Conv2d: 3-7                  [128, 64, 64, 64]         36,864
│    │    └─BatchNorm2d: 3-8             [128, 64, 64, 64]         128
│    │    └─ReLU: 3-9                    [128, 64, 64, 64]         --
│    │    └─Conv2d: 3-10                 [128, 64, 64, 64]         36,864
│    │    └─BatchNorm2d: 3-11            [128, 64, 64, 64]         128
│    │    └─ReLU: 3-12                   [128, 64, 64, 64]         --
├─Sequential: 1-6                        [128, 128, 32, 32]        --
│    └─ResidualBlock: 2-3                [128, 128, 32, 32]        --
│    │    └─Conv2d: 3-13                 [128, 128, 32, 32]        73,728
│    │    └─BatchNorm2d: 3-14            [128, 128, 32, 32]        256
│    │    └─ReLU: 3-15                   [128, 128, 32, 32]        --
│    │    └─Conv2d: 3-16                 [128, 128, 32, 32]        147,456
│    │    └─BatchNorm2d: 3-17            [128, 128, 32, 32]        256
│    │    └─Sequential: 3-18             [128, 128, 32, 32]        8,448
│    │    └─ReLU: 3-19                   [128, 128, 32, 32]        --
│    └─ResidualBlock: 2-4                [128, 128, 32, 32]        --
│    │    └─Conv2d: 3-20                 [128, 128, 32, 32]        147,456
│    │    └─BatchNorm2d: 3-21            [128, 128, 32, 32]        256
│    │    └─ReLU: 3-22                   [128, 128, 32, 32]        --
│    │    └─Conv2d: 3-23                 [128, 128, 32, 32]        147,456
│    │    └─BatchNorm2d: 3-24            [128, 128, 32, 32]        256
│    │    └─ReLU: 3-25                   [128, 128, 32, 32]        --
├─Sequential: 1-7                        [128, 256, 16, 16]        --
│    └─ResidualBlock: 2-5                [128, 256, 16, 16]        --
│    │    └─Conv2d: 3-26                 [128, 256, 16, 16]        294,912
│    │    └─BatchNorm2d: 3-27            [128, 256, 16, 16]        512
│    │    └─ReLU: 3-28                   [128, 256, 16, 16]        --
│    │    └─Conv2d: 3-29                 [128, 256, 16, 16]        589,824
│    │    └─BatchNorm2d: 3-30            [128, 256, 16, 16]        512
│    │    └─Sequential: 3-31             [128, 256, 16, 16]        33,280
│    │    └─ReLU: 3-32                   [128, 256, 16, 16]        --
│    └─ResidualBlock: 2-6                [128, 256, 16, 16]        --
│    │    └─Conv2d: 3-33                 [128, 256, 16, 16]        589,824
│    │    └─BatchNorm2d: 3-34            [128, 256, 16, 16]        512
│    │    └─ReLU: 3-35                   [128, 256, 16, 16]        --
│    │    └─Conv2d: 3-36                 [128, 256, 16, 16]        589,824
│    │    └─BatchNorm2d: 3-37            [128, 256, 16, 16]        512
│    │    └─ReLU: 3-38                   [128, 256, 16, 16]        --
├─Sequential: 1-8                        [128, 512, 8, 8]          --
│    └─ResidualBlock: 2-7                [128, 512, 8, 8]          --
│    │    └─Conv2d: 3-39                 [128, 512, 8, 8]          1,179,648
│    │    └─BatchNorm2d: 3-40            [128, 512, 8, 8]          1,024
│    │    └─ReLU: 3-41                   [128, 512, 8, 8]          --
│    │    └─Conv2d: 3-42                 [128, 512, 8, 8]          2,359,296
│    │    └─BatchNorm2d: 3-43            [128, 512, 8, 8]          1,024
│    │    └─Sequential: 3-44             [128, 512, 8, 8]          132,096
│    │    └─ReLU: 3-45                   [128, 512, 8, 8]          --
│    └─ResidualBlock: 2-8                [128, 512, 8, 8]          --
│    │    └─Conv2d: 3-46                 [128, 512, 8, 8]          2,359,296
│    │    └─BatchNorm2d: 3-47            [128, 512, 8, 8]          1,024
│    │    └─ReLU: 3-48                   [128, 512, 8, 8]          --
│    │    └─Conv2d: 3-49                 [128, 512, 8, 8]          2,359,296
│    │    └─BatchNorm2d: 3-50            [128, 512, 8, 8]          1,024
│    │    └─ReLU: 3-51                   [128, 512, 8, 8]          --
├─AdaptiveAvgPool2d: 1-9                 [128, 512, 1, 1]          --
==========================================================================================
Total params: 11,689,512
Trainable params: 11,689,512
Non-trainable params: 0
Total mult-adds (G): 303.20
==========================================================================================
Input size (MB): 100.66
Forward/backward pass size (MB): 6643.78
Params size (MB): 44.71
Estimated Total Size (MB): 6789.15
==========================================================================================
Training resnet on F_dataset with lr=0.0005
Epoch [   1/  50]  |  Train Loss: 0.97271  |  Validation Loss: 0.93134
Epoch [   2/  50]  |  Train Loss: 0.90883  |  Validation Loss: 0.74857
Epoch [   3/  50]  |  Train Loss: 0.67391  |  Validation Loss: 0.39008
Epoch [   4/  50]  |  Train Loss: 0.39773  |  Validation Loss: 0.18078
Epoch [   5/  50]  |  Train Loss: 0.26391  |  Validation Loss: 0.31392
Epoch [   6/  50]  |  Train Loss: 0.17697  |  Validation Loss: 0.13671
Epoch [   7/  50]  |  Train Loss: 0.10341  |  Validation Loss: 0.11782
Epoch [   8/  50]  |  Train Loss: 0.11882  |  Validation Loss: 0.08668
Epoch [   9/  50]  |  Train Loss: 0.09114  |  Validation Loss: 0.10706
Epoch [  10/  50]  |  Train Loss: 0.07671  |  Validation Loss: 0.23378
Epoch [  11/  50]  |  Train Loss: 0.09980  |  Validation Loss: 0.08777
Epoch [  12/  50]  |  Train Loss: 0.06367  |  Validation Loss: 0.30739
Epoch [  13/  50]  |  Train Loss: 0.06303  |  Validation Loss: 0.53562
========== Losses ==========
D:   0.3857  |  ND:   3.1972
D:   0.2223  |  ND:   3.1503
D:   0.4220  |  ND:   3.1639
D:   0.2783  |  ND:   3.1697
D:   0.2654  |  ND:   3.1345
D:   0.2343  |  ND:   3.1681
D:   0.3498  |  ND:   3.1818
D:   0.2555  |  ND:   3.1072
D:   0.2691  |  ND:   3.1564
D:   0.2462  |  ND:   3.2137

======== More stats ========
Accuracy:            100.00%
----------- Mean -----------
D:   0.2929  |  ND:   3.1643
