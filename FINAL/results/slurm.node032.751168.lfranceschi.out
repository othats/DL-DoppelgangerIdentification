Using cuda device
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
ResNet                                   [128, 512, 1, 1]          513,000
├─Conv2d: 1-1                            [128, 64, 128, 128]       9,408
├─BatchNorm2d: 1-2                       [128, 64, 128, 128]       128
├─ReLU: 1-3                              [128, 64, 128, 128]       --
├─MaxPool2d: 1-4                         [128, 64, 64, 64]         --
├─Sequential: 1-5                        [128, 64, 64, 64]         --
│    └─ResidualBlock: 2-1                [128, 64, 64, 64]         --
│    │    └─Conv2d: 3-1                  [128, 64, 64, 64]         36,864
│    │    └─BatchNorm2d: 3-2             [128, 64, 64, 64]         128
│    │    └─ReLU: 3-3                    [128, 64, 64, 64]         --
│    │    └─Conv2d: 3-4                  [128, 64, 64, 64]         36,864
│    │    └─BatchNorm2d: 3-5             [128, 64, 64, 64]         128
│    │    └─ReLU: 3-6                    [128, 64, 64, 64]         --
│    └─ResidualBlock: 2-2                [128, 64, 64, 64]         --
│    │    └─Conv2d: 3-7                  [128, 64, 64, 64]         36,864
│    │    └─BatchNorm2d: 3-8             [128, 64, 64, 64]         128
│    │    └─ReLU: 3-9                    [128, 64, 64, 64]         --
│    │    └─Conv2d: 3-10                 [128, 64, 64, 64]         36,864
│    │    └─BatchNorm2d: 3-11            [128, 64, 64, 64]         128
│    │    └─ReLU: 3-12                   [128, 64, 64, 64]         --
├─Sequential: 1-6                        [128, 128, 32, 32]        --
│    └─ResidualBlock: 2-3                [128, 128, 32, 32]        --
│    │    └─Conv2d: 3-13                 [128, 128, 32, 32]        73,728
│    │    └─BatchNorm2d: 3-14            [128, 128, 32, 32]        256
│    │    └─ReLU: 3-15                   [128, 128, 32, 32]        --
│    │    └─Conv2d: 3-16                 [128, 128, 32, 32]        147,456
│    │    └─BatchNorm2d: 3-17            [128, 128, 32, 32]        256
│    │    └─Sequential: 3-18             [128, 128, 32, 32]        8,448
│    │    └─ReLU: 3-19                   [128, 128, 32, 32]        --
│    └─ResidualBlock: 2-4                [128, 128, 32, 32]        --
│    │    └─Conv2d: 3-20                 [128, 128, 32, 32]        147,456
│    │    └─BatchNorm2d: 3-21            [128, 128, 32, 32]        256
│    │    └─ReLU: 3-22                   [128, 128, 32, 32]        --
│    │    └─Conv2d: 3-23                 [128, 128, 32, 32]        147,456
│    │    └─BatchNorm2d: 3-24            [128, 128, 32, 32]        256
│    │    └─ReLU: 3-25                   [128, 128, 32, 32]        --
├─Sequential: 1-7                        [128, 256, 16, 16]        --
│    └─ResidualBlock: 2-5                [128, 256, 16, 16]        --
│    │    └─Conv2d: 3-26                 [128, 256, 16, 16]        294,912
│    │    └─BatchNorm2d: 3-27            [128, 256, 16, 16]        512
│    │    └─ReLU: 3-28                   [128, 256, 16, 16]        --
│    │    └─Conv2d: 3-29                 [128, 256, 16, 16]        589,824
│    │    └─BatchNorm2d: 3-30            [128, 256, 16, 16]        512
│    │    └─Sequential: 3-31             [128, 256, 16, 16]        33,280
│    │    └─ReLU: 3-32                   [128, 256, 16, 16]        --
│    └─ResidualBlock: 2-6                [128, 256, 16, 16]        --
│    │    └─Conv2d: 3-33                 [128, 256, 16, 16]        589,824
│    │    └─BatchNorm2d: 3-34            [128, 256, 16, 16]        512
│    │    └─ReLU: 3-35                   [128, 256, 16, 16]        --
│    │    └─Conv2d: 3-36                 [128, 256, 16, 16]        589,824
│    │    └─BatchNorm2d: 3-37            [128, 256, 16, 16]        512
│    │    └─ReLU: 3-38                   [128, 256, 16, 16]        --
├─Sequential: 1-8                        [128, 512, 8, 8]          --
│    └─ResidualBlock: 2-7                [128, 512, 8, 8]          --
│    │    └─Conv2d: 3-39                 [128, 512, 8, 8]          1,179,648
│    │    └─BatchNorm2d: 3-40            [128, 512, 8, 8]          1,024
│    │    └─ReLU: 3-41                   [128, 512, 8, 8]          --
│    │    └─Conv2d: 3-42                 [128, 512, 8, 8]          2,359,296
│    │    └─BatchNorm2d: 3-43            [128, 512, 8, 8]          1,024
│    │    └─Sequential: 3-44             [128, 512, 8, 8]          132,096
│    │    └─ReLU: 3-45                   [128, 512, 8, 8]          --
│    └─ResidualBlock: 2-8                [128, 512, 8, 8]          --
│    │    └─Conv2d: 3-46                 [128, 512, 8, 8]          2,359,296
│    │    └─BatchNorm2d: 3-47            [128, 512, 8, 8]          1,024
│    │    └─ReLU: 3-48                   [128, 512, 8, 8]          --
│    │    └─Conv2d: 3-49                 [128, 512, 8, 8]          2,359,296
│    │    └─BatchNorm2d: 3-50            [128, 512, 8, 8]          1,024
│    │    └─ReLU: 3-51                   [128, 512, 8, 8]          --
├─AdaptiveAvgPool2d: 1-9                 [128, 512, 1, 1]          --
==========================================================================================
Total params: 11,689,512
Trainable params: 11,689,512
Non-trainable params: 0
Total mult-adds (G): 303.20
==========================================================================================
Input size (MB): 100.66
Forward/backward pass size (MB): 6643.78
Params size (MB): 44.71
Estimated Total Size (MB): 6789.15
==========================================================================================
Training resnet on dataset with lr=0.0005
Epoch [   1/  50]  |  Train Loss: 0.96192  |  Validation Loss: 0.72007
Epoch [   2/  50]  |  Train Loss: 0.65643  |  Validation Loss: 0.47834
Epoch [   3/  50]  |  Train Loss: 0.33753  |  Validation Loss: 0.36998
Epoch [   4/  50]  |  Train Loss: 0.15254  |  Validation Loss: 0.34076
Epoch [   5/  50]  |  Train Loss: 0.08195  |  Validation Loss: 0.23888
Epoch [   6/  50]  |  Train Loss: 0.06746  |  Validation Loss: 0.27220
Epoch [   7/  50]  |  Train Loss: 0.03870  |  Validation Loss: 0.40420
Epoch [   8/  50]  |  Train Loss: 0.03217  |  Validation Loss: 0.36807
Epoch [   9/  50]  |  Train Loss: 0.05429  |  Validation Loss: 0.37541
========== Losses ==========
D:   1.1605  |  ND:   3.5258
D:   1.0034  |  ND:   3.6586
D:   1.7786  |  ND:   3.6402
D:   2.0388  |  ND:   3.7288
D:   1.3191  |  ND:   3.5980
D:   1.1119  |  ND:   3.5853
D:   2.4654  |  ND:   3.7628
D:   1.3245  |  ND:   3.6427
D:   1.2517  |  ND:   3.6395
D:   2.7074  |  ND:   3.7994

======== More stats ========
Accuracy:            100.00%
----------- Mean -----------
D:   1.7097  |  ND:   3.6883
